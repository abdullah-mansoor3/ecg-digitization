{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81bd4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "NUM_IMAGES = 20\n",
    "CONF_THRESHOLD = 0.7\n",
    "\n",
    "TEST_IMAGE_DIR = '../data/segmentation-dataset-6by2/train-augmented/images'\n",
    "SAVE_ROOT = '../../data/yolo-segmentation-results'\n",
    "MODEL_PATH = '../../models/yolo-segmentation-weights.pt'\n",
    "\n",
    "# Load model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Read image files\n",
    "image_files = [f for f in os.listdir(TEST_IMAGE_DIR) if f.endswith((\".jpg\", \".png\"))]\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "# Mapping from class ID to name\n",
    "class_names = model.names\n",
    "\n",
    "ORDERED_WAVE_LABELS = ['I', 'V1', 'II', 'V2', 'III', 'V3',\n",
    "                       'aVL', 'V4', 'aVR', 'V5', 'aVF', 'V6', 'II_ext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e5bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/1926_6by2_aug0.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 210.8ms\n",
      "Speed: 2.0ms preprocess, 210.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/686_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 236.9ms\n",
      "Speed: 4.2ms preprocess, 236.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/1566_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 235.2ms\n",
      "Speed: 6.8ms preprocess, 235.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/314_6by2_aug2.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V6, 193.4ms\n",
      "Speed: 2.7ms preprocess, 193.4ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/458_6by2_aug2.jpg: 320x640 12 lead_containers, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 192.1ms\n",
      "Speed: 2.1ms preprocess, 192.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/46_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 216.3ms\n",
      "Speed: 2.0ms preprocess, 216.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/502_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 201.6ms\n",
      "Speed: 5.0ms preprocess, 201.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/1762_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 225.0ms\n",
      "Speed: 2.7ms preprocess, 225.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/78_6by2_aug2.jpg: 320x640 12 lead_containers, 1 label_II, 1 label_III, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 215.4ms\n",
      "Speed: 4.5ms preprocess, 215.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/1778_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 209.6ms\n",
      "Speed: 3.3ms preprocess, 209.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/906_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 203.0ms\n",
      "Speed: 9.6ms preprocess, 203.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/694_6by2_aug2.jpg: 320x640 12 lead_containers, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 205.3ms\n",
      "Speed: 3.2ms preprocess, 205.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/1254_6by2_aug1.jpg: 320x640 11 lead_containers, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 247.1ms\n",
      "Speed: 6.3ms preprocess, 247.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/38_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 220.0ms\n",
      "Speed: 3.2ms preprocess, 220.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/lead-segmentation/scripts/../data/segmentation-dataset-6by2/train-augmented/images/806_6by2_aug1.jpg: 320x640 12 lead_containers, 1 label_I, 1 label_III, 1 label_aVR, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 227.2ms\n",
      "Speed: 2.9ms preprocess, 227.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "def merge_boxes(box1, box2):\n",
    "    x1 = min(box1[0], box2[0])\n",
    "    y1 = min(box1[1], box2[1])\n",
    "    x2 = max(box1[2], box2[2])\n",
    "    y2 = max(box1[3], box2[3])\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def sort_wave_boxes(boxes):\n",
    "    # Group into rows based on y-coordinate proximity (30 pixel threshold)\n",
    "    rows = []\n",
    "    for box in sorted(boxes, key=lambda b: b[1]):  # sort by y1\n",
    "        placed = False\n",
    "        for row in rows:\n",
    "            if abs(row[-1][1] - box[1]) < 30:  # y1 close enough\n",
    "                row.append(box)\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            rows.append([box])\n",
    "    # Sort each row left to right\n",
    "    for row in rows:\n",
    "        row.sort(key=lambda b: b[0])\n",
    "    # Flatten and return\n",
    "    flat = [b for row in rows for b in row]\n",
    "    return flat\n",
    "\n",
    "for idx in range(15):\n",
    "    image_file = image_files[idx]\n",
    "    image_path = os.path.join(TEST_IMAGE_DIR, image_file)\n",
    "    base_name = os.path.splitext(image_file)[0]\n",
    "\n",
    "    # Inference\n",
    "    results = model(image_path)[0]\n",
    "\n",
    "    # Read and prepare image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create save folder\n",
    "    image_save_dir = os.path.join(SAVE_ROOT, base_name)\n",
    "    os.makedirs(image_save_dir, exist_ok=True)\n",
    "\n",
    "    # Get class 0 boxes above threshold\n",
    "    wave_boxes = []\n",
    "    for box in results.boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if conf >= CONF_THRESHOLD and cls_id == 0:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            wave_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    # Special handling for II extended\n",
    "    if len(wave_boxes) == 14:\n",
    "        wave_boxes[-2:] = [merge_boxes(wave_boxes[-2], wave_boxes[-1])]\n",
    "\n",
    "    # Sort in row-wise (top to bottom, then left to right) order\n",
    "    wave_boxes = sort_wave_boxes(wave_boxes)\n",
    "\n",
    "    # Save full image with real class labels\n",
    "    for box in results.boxes:\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < CONF_THRESHOLD:\n",
    "            continue\n",
    "        cls_id = int(box.cls[0])\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = f\"{class_names[cls_id]} ({conf:.2f})\"\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(img_rgb, label, (x1, max(y1 - 10, 10)), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)\n",
    "\n",
    "    # Save cropped waves with correct label names\n",
    "    for i, box in enumerate(wave_boxes):\n",
    "        if i >= len(ORDERED_WAVE_LABELS):\n",
    "            break\n",
    "        label = ORDERED_WAVE_LABELS[i]\n",
    "        x1, y1, x2, y2 = box\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "        crop_path = os.path.join(image_save_dir, f\"{label}.jpg\")\n",
    "        cv2.imwrite(crop_path, crop, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "\n",
    "    # Save full annotated image\n",
    "    full_img_path = os.path.join(image_save_dir, \"full.jpg\")\n",
    "    cv2.imwrite(full_img_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR), [cv2.IMWRITE_JPEG_QUALITY, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd8fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
