{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8be5525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah-bin-mansoor/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats import pearsonr\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scripts.grid_detection import get_grid_square_size\n",
    "from scripts.extract_wave import WaveExtractor\n",
    "from scripts.digititze import process_ecg_mask\n",
    "from scripts.lead_segmentation import init_model as init_lead_model, inference_and_label_and_crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db83f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load configs ---\n",
    "with open('./configs/lead_segmentation.yaml', 'r') as f:\n",
    "    lead_cfg = yaml.safe_load(f)\n",
    "with open('./configs/wave_extraction.yaml', 'r') as f:\n",
    "    wave_cfg = yaml.safe_load(f)\n",
    "with open('./configs/grid_detection.yaml', 'r') as f:\n",
    "    grid_cfg = yaml.safe_load(f)\n",
    "with open('./configs/digitize.yaml', 'r') as f:\n",
    "    digitize_cfg = yaml.safe_load(f)\n",
    "\n",
    "# --- Paths ---\n",
    "INPUT_ROOT = '../data/digitization-dataset/digitization-dataset'\n",
    "CROPPED_SAVE_DIR = lead_cfg['output_dir']\n",
    "GRID_KERNEL = grid_cfg.get('closing_kernel', 10)\n",
    "GRID_LENGTH_FRAC = grid_cfg.get('length_frac', 0.05)\n",
    "WAVE_WEIGHTS_PATH = wave_cfg['weights_path']\n",
    "WAVE_DEVICE = wave_cfg.get('device', 'cpu')\n",
    "FINAL_OUTPUT_DIR = './data/test'\n",
    "YOLO_WEIGHTS_PATH = lead_cfg['model_path']\n",
    "os.makedirs(CROPPED_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3e72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing wave extractor...\n",
      "Wave extractor initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scripts.grid_detection import get_grid_square_size\n",
    "from scripts.digititze import process_ecg_mask\n",
    "\n",
    "# --- Constants ---\n",
    "lead_names = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "GRID_KERNEL = grid_cfg.get('closing_kernel', 10)\n",
    "GRID_LENGTH_FRAC = grid_cfg.get('length_frac', 0.05)\n",
    "\n",
    "# --- Load models ---\n",
    "lead_model = init_lead_model(lead_cfg['model_path'])\n",
    "wave_extractor = WaveExtractor(WAVE_WEIGHTS_PATH, device=WAVE_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0740cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluation helpers ---\n",
    "def match_length(a, b):\n",
    "    n = min(len(a), len(b))\n",
    "    return a[:n], b[:n]\n",
    "\n",
    "def scalar_euclid(a, b):\n",
    "    # convert floats to 1‚Äëelement 1D arrays\n",
    "    return euclidean([a], [b])\n",
    "\n",
    "\n",
    "def evaluate_signals(pred, gt):\n",
    "    p = np.ravel(pred).astype(float)\n",
    "    g = np.ravel(gt).astype(float)\n",
    "    p, g = match_length(p, g)\n",
    "    # MSE & Pearson\n",
    "    mse  = mean_squared_error(g, p)\n",
    "    corr = pearsonr(g, p)[0] if len(g) > 2 else np.nan\n",
    "    # DTW on plain lists\n",
    "    g = g.tolist()\n",
    "    p = p.tolist()\n",
    "\n",
    "    dtw_dist, _ = fastdtw(g, p, dist=scalar_euclid)\n",
    "    return {\"MSE\": mse, \"Correlation\": corr, \"DTW\": dtw_dist}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e01a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/abdullah-bin-mansoor/Desktop/ECG Project/full-pipeline/../data/digitization-dataset/digitization-dataset/1670_6by2/1670_6by2.jpg: 320x640 12 lead_containers, 1 label_II, 1 label_III, 1 label_aVR, 1 label_aVL, 1 label_aVF, 1 label_V1, 1 label_V2, 1 label_V3, 1 label_V4, 1 label_V5, 1 label_V6, 217.8ms\n",
      "Speed: 2.8ms preprocess, 217.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "lead_names = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "\n",
    "GRID_KERNEL = 10\n",
    "GRID_LENGTH_FRAC = 0.05\n",
    "\n",
    "folders = [d for d in os.listdir(INPUT_ROOT) if '6by2' in d and os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
    "total_folders = len(folders)\n",
    "total_slots = total_folders * len(lead_names)\n",
    "detected_count = 0\n",
    "per_lead_detect = {ln: 0 for ln in lead_names}\n",
    "metrics_detected = []\n",
    "metrics_all = []\n",
    "\n",
    "for idx, fld in enumerate(folders, 1):\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"{idx}/{total_folders} folders processed‚Ä¶\")\n",
    "\n",
    "    fld_path = os.path.join(INPUT_ROOT, fld)\n",
    "    img_path = os.path.join(fld_path, f\"{fld}.jpg\")\n",
    "\n",
    "    if not os.path.isfile(img_path):\n",
    "        print(f\"‚ö†Ô∏è Missing image: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- Step 1: Lead Segmentation ---\n",
    "    crops, _ = inference_and_label_and_crop(\n",
    "        lead_model, img_path, output_dir=fld_path, conf_threshold=lead_cfg['conf_threshold']\n",
    "    )\n",
    "\n",
    "    # Mimic main pipeline: save paths\n",
    "    all_cropped_leads = []\n",
    "    for crop_img, label in crops:\n",
    "        crop_path = os.path.join(fld_path, f\"{fld}_{label}.jpg\")\n",
    "        cv2.imwrite(crop_path, crop_img)\n",
    "        all_cropped_leads.append((crop_path, label))\n",
    "\n",
    "    # --- Step 2: Grid Detection ---\n",
    "    lead_to_sq = {}\n",
    "    for crop_path, label in all_cropped_leads:\n",
    "        img = cv2.imread(crop_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Failed to read {crop_path}\")\n",
    "            continue\n",
    "        sq = get_grid_square_size(img, closing_kernel=GRID_KERNEL, length_frac=GRID_LENGTH_FRAC)\n",
    "        lead_to_sq[label] = sq\n",
    "\n",
    "    # --- Step 3: Wave Extraction ---\n",
    "    lead_to_mask = {}\n",
    "    for crop_path, label in all_cropped_leads:\n",
    "        mask = wave_extractor.extract_wave(crop_path)\n",
    "        lead_to_mask[label] = mask\n",
    "\n",
    "    # --- Step 4: Digitization ---\n",
    "    lead_waveforms = {}\n",
    "    for crop_path, label in all_cropped_leads:\n",
    "        sq = lead_to_sq.get(label)\n",
    "        mask = lead_to_mask.get(label)\n",
    "        if sq is None or mask is None:\n",
    "            continue\n",
    "        wf = process_ecg_mask(mask, sq)\n",
    "        lead_waveforms[label] = wf\n",
    "\n",
    "    # --- Step 5: Compare to Ground-Truth ---\n",
    "    results_det = {}\n",
    "    results_all = {}\n",
    "\n",
    "    for i_lead, lead_label in enumerate(lead_names):\n",
    "        gt_file = os.path.join(fld_path, f\"{fld}_lead_{i_lead}.json\")\n",
    "        if not os.path.isfile(gt_file):\n",
    "            continue\n",
    "\n",
    "        gt_wave = np.array(json.load(open(gt_file)))\n",
    "\n",
    "        pred = None\n",
    "        for lbl, wf in lead_waveforms.items():\n",
    "            if lbl.lower() == lead_label.lower():\n",
    "                pred = wf\n",
    "                break\n",
    "\n",
    "        if pred is not None:\n",
    "            detected_count += 1\n",
    "            per_lead_detect[lead_label] += 1\n",
    "            m = evaluate_signals(pred, gt_wave)\n",
    "            results_det[lead_label] = m\n",
    "            metrics_detected.append(m)\n",
    "\n",
    "        # Always evaluate something (zeros if missed)\n",
    "        p0 = pred if pred is not None else np.zeros_like(gt_wave, dtype=float)\n",
    "        m_all = evaluate_signals(p0, gt_wave)\n",
    "        results_all[lead_label] = m_all\n",
    "        metrics_all.append(m_all)\n",
    "\n",
    "    # --- Per-folder Summary ---\n",
    "    print(f\"\\nüìÅ {fld}: {len(results_det)}/{len(lead_names)} leads detected\")\n",
    "    for ln, m in results_det.items():\n",
    "        print(f\"  {ln}: MSE={m['MSE']:.4f}, Corr={m['Correlation']:.3f}, DTW={m['DTW']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fa3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
